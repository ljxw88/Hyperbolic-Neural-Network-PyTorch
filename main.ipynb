{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "# import geoopt\n",
    "import manifolds\n",
    "import layers.hyp_layers as hyp_layers\n",
    "import utils.math_utils as pmath\n",
    "import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.796129    2.1868322 ]\n",
      " [ 1.7100279   2.8140442 ]\n",
      " [ 1.235987    2.3387034 ]\n",
      " [ 2.1493998   3.2302608 ]\n",
      " [ 2.0747974   2.3686128 ]\n",
      " [ 0.8994112   3.916121  ]\n",
      " [ 1.9367622   0.44875455]\n",
      " [ 1.9738387   3.5876145 ]\n",
      " [ 4.6340346   2.8736534 ]\n",
      " [ 3.152142    1.6565876 ]\n",
      " [ 3.1138315   2.207151  ]\n",
      " [ 3.734939    2.0592616 ]\n",
      " [ 0.9254284   3.0757728 ]\n",
      " [ 2.0052185   2.6898935 ]\n",
      " [ 2.1260293   1.811782  ]\n",
      " [ 2.0144053   1.8061991 ]\n",
      " [ 0.8387127   2.1443353 ]\n",
      " [ 2.1168306   1.989832  ]\n",
      " [ 2.102544    2.3392096 ]\n",
      " [ 1.3232805   3.1415274 ]\n",
      " [ 1.2104527   1.941552  ]\n",
      " [ 2.8299012   1.1343079 ]\n",
      " [ 1.4139744   3.0992694 ]\n",
      " [ 2.505512    0.7896763 ]\n",
      " [ 0.31563783  1.445152  ]\n",
      " [ 1.658386    0.17534566]\n",
      " [ 1.8758687   2.3231602 ]\n",
      " [ 2.3809705   2.725052  ]\n",
      " [ 2.020403    1.7318258 ]\n",
      " [ 3.1010246   1.7558494 ]\n",
      " [ 4.3841953   1.9918698 ]\n",
      " [ 0.79744947  4.2572274 ]\n",
      " [ 1.0052218   2.3976593 ]\n",
      " [ 1.8879421   2.8303652 ]\n",
      " [ 1.185845    2.4496427 ]\n",
      " [ 0.8573315   3.5953608 ]\n",
      " [-0.7238126   0.3117702 ]\n",
      " [ 3.5693266   1.5318902 ]\n",
      " [ 1.4499582   1.7009442 ]\n",
      " [ 0.6185936   1.4513636 ]\n",
      " [ 0.6066681   1.9261781 ]\n",
      " [ 3.0753107   2.1113894 ]\n",
      " [ 0.990672    2.3126953 ]\n",
      " [ 1.463839    2.779244  ]\n",
      " [ 2.2218943   3.0703926 ]\n",
      " [ 2.089249    2.2350044 ]\n",
      " [ 3.823492    3.1494932 ]\n",
      " [ 0.21902478  1.393078  ]\n",
      " [ 0.765715    2.0265503 ]\n",
      " [ 1.7710831   1.3653753 ]\n",
      " [-0.05028462  1.6507887 ]\n",
      " [ 3.943972    2.1556404 ]\n",
      " [ 2.4484744   0.8437743 ]\n",
      " [ 2.6202214   2.2698786 ]\n",
      " [ 2.8327143   1.6408107 ]\n",
      " [ 2.8151565   3.15946   ]\n",
      " [ 1.9829254   1.7722799 ]\n",
      " [ 2.9287963   2.3303027 ]\n",
      " [ 1.3373823   2.1994288 ]\n",
      " [ 0.2654462   1.5886809 ]\n",
      " [ 1.8691473   1.5619358 ]\n",
      " [ 0.41850173  3.676612  ]\n",
      " [ 0.46123838  3.697095  ]\n",
      " [ 1.8008988   2.0492427 ]\n",
      " [ 1.6030642   1.6067363 ]\n",
      " [ 1.4242791   0.47150934]\n",
      " [ 3.2417216   2.266068  ]\n",
      " [ 3.2519152   0.6490704 ]\n",
      " [ 3.6603227   0.9036876 ]\n",
      " [ 3.1125216   1.0771744 ]\n",
      " [ 2.1530237   2.650937  ]\n",
      " [ 3.6591654   4.6281357 ]\n",
      " [ 0.8849907   1.7972561 ]\n",
      " [ 3.398322    3.7730293 ]\n",
      " [ 0.8485302   2.5217688 ]\n",
      " [ 1.6824961  -1.8165734 ]\n",
      " [ 3.5049696   1.453588  ]\n",
      " [ 1.8675326   2.9761376 ]\n",
      " [ 2.4322777   2.3707201 ]\n",
      " [ 2.4508312   1.7828256 ]\n",
      " [ 1.6978334   1.5461953 ]\n",
      " [ 2.7038136   4.2878966 ]\n",
      " [ 1.6054481   1.2498412 ]\n",
      " [ 1.8922704   2.2271616 ]\n",
      " [ 3.7611647   1.6113207 ]\n",
      " [ 0.4254564   3.4714046 ]\n",
      " [ 3.0332565   1.7924606 ]\n",
      " [ 1.7537094   2.3045056 ]\n",
      " [ 1.6227527   2.1646588 ]\n",
      " [ 2.0694323   3.6566243 ]\n",
      " [ 2.1398258   1.3445258 ]\n",
      " [ 2.2903786   2.0206249 ]\n",
      " [ 1.21523     2.2537975 ]\n",
      " [ 2.0702672   2.8518467 ]\n",
      " [ 1.9165226   1.71029   ]\n",
      " [-0.51494765  1.7935691 ]\n",
      " [ 0.51681745  3.0959463 ]\n",
      " [ 0.65894544  3.1842303 ]\n",
      " [ 1.7166508   2.110123  ]\n",
      " [ 0.054389    1.8602171 ]\n",
      " [-2.6123176  -3.680748  ]\n",
      " [-3.0103562  -3.8654602 ]\n",
      " [-1.7825776  -1.532874  ]\n",
      " [-1.4252923  -2.5689466 ]\n",
      " [-2.4864237  -2.0340338 ]\n",
      " [-1.0521035  -0.8787153 ]\n",
      " [-1.961036    0.37753177]\n",
      " [-1.8360364  -3.4336    ]\n",
      " [-3.5780225  -2.0754883 ]\n",
      " [-3.7588947  -2.7107358 ]\n",
      " [-4.603824   -1.9408276 ]\n",
      " [-1.053118   -2.411901  ]\n",
      " [-3.1021142  -2.8359227 ]\n",
      " [-2.903043   -1.2219143 ]\n",
      " [-4.4993286  -3.1184602 ]\n",
      " [-1.6701573  -1.3045466 ]\n",
      " [ 0.6417451  -1.519414  ]\n",
      " [-2.462748   -2.7218518 ]\n",
      " [-1.5677831  -2.2296667 ]\n",
      " [-2.0029674  -1.1453364 ]\n",
      " [-1.5322974  -2.254702  ]\n",
      " [-3.101242   -2.4588513 ]\n",
      " [-2.5266047  -1.6128353 ]\n",
      " [-1.8938704  -3.6183984 ]\n",
      " [-2.0517514  -1.8021958 ]\n",
      " [-1.3263346  -2.630045  ]\n",
      " [-1.4193058  -1.1787457 ]\n",
      " [-2.8370028  -1.1017408 ]\n",
      " [-1.4493638  -3.5112002 ]\n",
      " [-1.1335292  -2.377978  ]\n",
      " [-2.5683646  -1.2240334 ]\n",
      " [-2.5542102  -2.3112524 ]\n",
      " [-1.317951   -0.40857565]\n",
      " [-2.6882653  -2.5773225 ]\n",
      " [-2.4578779  -2.9352856 ]\n",
      " [-1.1606913  -1.7128527 ]\n",
      " [-1.7228726  -3.824916  ]\n",
      " [-3.2275338  -4.3568907 ]\n",
      " [-2.5124826  -1.7083168 ]\n",
      " [-1.9956585  -0.99687564]\n",
      " [-1.2373543  -3.5456352 ]\n",
      " [-3.7576256  -1.7758391 ]\n",
      " [-1.5769142  -2.2355413 ]\n",
      " [-1.308073    0.4902637 ]\n",
      " [-3.4278693  -1.3605378 ]\n",
      " [-2.9627924  -3.2967267 ]\n",
      " [-2.8972518  -3.4482732 ]\n",
      " [-3.6420548  -1.40786   ]\n",
      " [-0.33849537 -0.87948346]\n",
      " [ 1.005753   -1.9573668 ]\n",
      " [-2.5618973  -2.751611  ]\n",
      " [-2.5164583  -3.0995512 ]\n",
      " [-2.098265   -1.1434436 ]\n",
      " [ 0.23561645 -0.9177656 ]\n",
      " [-1.877609   -2.7515502 ]\n",
      " [-1.8870925  -2.6530151 ]\n",
      " [-2.371892   -0.794736  ]\n",
      " [-0.9938607  -3.2509437 ]\n",
      " [-1.8285146  -2.9082646 ]\n",
      " [-1.8706801  -2.9013367 ]\n",
      " [-1.688658   -1.32965   ]\n",
      " [-2.6293643  -2.0525532 ]\n",
      " [-2.9691262  -2.3025181 ]\n",
      " [-1.7041585  -1.9862913 ]\n",
      " [-1.7688916  -0.980284  ]\n",
      " [-1.6118381  -2.1546905 ]\n",
      " [-0.07531238 -2.9873397 ]\n",
      " [-0.31890512 -2.144034  ]\n",
      " [-2.7869222  -2.329491  ]\n",
      " [-2.3418894  -3.280302  ]\n",
      " [-2.13028    -2.7635548 ]\n",
      " [-1.560317   -1.6704694 ]\n",
      " [-2.5685074  -4.3606024 ]\n",
      " [-1.5052083  -2.6256475 ]\n",
      " [-1.3384345  -2.524786  ]\n",
      " [-1.7190882  -2.6370027 ]\n",
      " [-2.9090118  -2.7061758 ]\n",
      " [-2.0882745  -2.1954272 ]\n",
      " [-1.2579446   0.40205526]\n",
      " [-2.300694   -1.904287  ]\n",
      " [-2.3791625  -0.09252882]\n",
      " [-0.98840094 -1.1239507 ]\n",
      " [-1.8285724  -2.5465236 ]\n",
      " [-3.297989    0.17701459]\n",
      " [-2.9230323  -1.5540215 ]\n",
      " [-1.4138863  -4.452969  ]\n",
      " [-3.6537106  -1.3096685 ]\n",
      " [-2.0963373  -1.1946362 ]\n",
      " [-1.9958113  -2.5689545 ]\n",
      " [-0.43059123 -1.8891829 ]\n",
      " [-3.2460804  -1.2026143 ]\n",
      " [-1.9612975  -0.9858296 ]\n",
      " [-2.2726989  -1.5843744 ]\n",
      " [-1.6994163  -3.5398235 ]\n",
      " [-0.4999547  -2.0570996 ]\n",
      " [-2.0430126  -2.6184125 ]\n",
      " [-1.6685572  -2.6641934 ]\n",
      " [-3.4529145  -2.4088182 ]\n",
      " [-1.5503037  -2.8560727 ]\n",
      " [-0.9654136  -1.476455  ]]\n"
     ]
    }
   ],
   "source": [
    "n_data = torch.ones(100, 2)\n",
    "x0 = torch.normal(2*n_data, 1)\n",
    "y0 = torch.zeros(100)\n",
    "x1 = torch.normal(-2*n_data, 1)\n",
    "y1 = torch.ones(100)\n",
    "\n",
    "x = torch.cat((x0, x1), 0).type(torch.FloatTensor)  # FloatTensor = 32-bit floating\n",
    "y = torch.cat((y0, y1), ).type(torch.LongTensor)    # LongTensor = 64-bit integer\n",
    "\n",
    "print(x.detach().numpy())\n",
    "plt.scatter(x.detach().numpy(), y.detach().numpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "args\n",
    "\"\"\"\n",
    "class config_args():\n",
    "    def __init__(self):\n",
    "        self.manifold = 'PoincareBall' # which manifold to use, can be any of [Euclidean, Hyperboloid, PoincareBall]\n",
    "        self.dropout = 0.0\n",
    "        self.bias = 1\n",
    "        self.c = 1.0\n",
    "        self.num_layers = 2\n",
    "        self.cuda = -1 # which cuda device to use (-1 for cpu training)\n",
    "        self.act = 'relu'\n",
    "        self.dim = 128 # embedding dimension\n",
    "        self.task = 'None'\n",
    "        self.optimizer = 'RiemannianAdam' # which optimizer to use, can be any of [Adam, RiemannianAdam]\n",
    "        self.lr = 0.01\n",
    "        self.weight_decay = 0.\n",
    "    \n",
    "args = config_args()\n",
    "args.feat_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder abstract class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.c = c\n",
    "\n",
    "    def encode(self, x, adj):\n",
    "        if self.encode_graph:\n",
    "            input = (x, adj)\n",
    "            output, _ = self.layers.forward(input)\n",
    "        else:\n",
    "            output = self.layers.forward(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HNN(Encoder):\n",
    "    \"\"\"\n",
    "    Hyperbolic Neural Networks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c, args):\n",
    "        super(HNN, self).__init__(c)\n",
    "        self.manifold = getattr(manifolds, args.manifold)()\n",
    "        assert args.num_layers > 1\n",
    "        dims, acts, _ = hyp_layers.get_dim_act_curv(args)\n",
    "        hnn_layers = []\n",
    "        for i in range(len(dims) - 1):\n",
    "            in_dim, out_dim = dims[i], dims[i + 1]\n",
    "            act = acts[i]\n",
    "            hnn_layers.append(\n",
    "                    hyp_layers.HNNLayer(\n",
    "                            self.manifold, in_dim, out_dim, self.c, args.dropout, act, args.bias)\n",
    "            )\n",
    "        self.layers = nn.Sequential(*hnn_layers)\n",
    "        self.encode_graph = False\n",
    "\n",
    "    def encode(self, x, adj):\n",
    "        x_hyp = self.manifold.proj(self.manifold.expmap0(self.manifold.proj_tan0(x, self.c), c=self.c), c=self.c)\n",
    "        return super(HNN, self).encode(x_hyp, adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder abstract class for node classification tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.c = c\n",
    "\n",
    "    def decode(self, x, adj):\n",
    "        if self.decode_adj:\n",
    "            input = (x, adj)\n",
    "            probs, _ = self.cls.forward(input)\n",
    "        else:\n",
    "            probs = self.cls.forward(x)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearDecoder(Decoder):\n",
    "    \"\"\"\n",
    "    MLP Decoder for Hyperbolic/Euclidean node classification models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c, args):\n",
    "        super(LinearDecoder, self).__init__(c)\n",
    "        self.manifold = getattr(manifolds, args.manifold)()\n",
    "        self.input_dim = args.dim\n",
    "        self.output_dim = args.n_classes\n",
    "        self.bias = args.bias\n",
    "        self.cls = hyp_layers.Linear(self.input_dim, self.output_dim, args.dropout, lambda x: x, self.bias)\n",
    "        self.decode_adj = False\n",
    "\n",
    "    def decode(self, x, adj):\n",
    "        h = self.manifold.proj_tan0(self.manifold.logmap0(x, c=self.c), c=self.c)\n",
    "        return super(LinearDecoder, self).decode(h, adj)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}, c={}'.format(\n",
    "                self.input_dim, self.output_dim, self.bias, self.c\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.manifold_name = args.manifold\n",
    "        if args.c is not None:\n",
    "            self.c = torch.tensor([args.c])\n",
    "            if not args.cuda == -1:\n",
    "                self.c = self.c.to(args.device)\n",
    "        else:\n",
    "            self.c = nn.Parameter(torch.Tensor([1.]))\n",
    "        self.manifold = getattr(manifolds, self.manifold_name)()\n",
    "        if self.manifold.name == 'Hyperboloid':\n",
    "            args.feat_dim = args.feat_dim + 1\n",
    "        self.encoder = HNN(self.c, args)\n",
    "    \n",
    "    def encode(self, x, adj = None):\n",
    "        if self.manifold.name == 'Hyperboloid':\n",
    "            o = torch.zeros_like(x)\n",
    "            x = torch.cat([o[:, 0:1], x], dim=1)\n",
    "        h = self.encoder.encode(x, adj)\n",
    "        return h\n",
    "\n",
    "    def decode(self, h)\n",
    "    \n",
    "    def compute_metrics(self, embeddings, data, split):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel(args)\n",
    "optimizer = getattr(optimizers, args.optimizer)(params=model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "#         optimizer,\n",
    "#         step_size=int(args.lr_reduce_freq),\n",
    "#         gamma=float(args.gamma)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model.encode(data...)\n",
    "    loss = F.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # lr_scheduler.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a25e8b4ed18c5060484a740a4dd6994d873f28ba8126f8c996cd8f6c608d492"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('research')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
